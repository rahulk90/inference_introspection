{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Visualize Samples from the model\n",
    "import sys, os, glob\n",
    "from collections import OrderedDict\n",
    "sys.path.append('../../')\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['lines.linewidth']=5\n",
    "mpl.rcParams['lines.markersize']=15\n",
    "mpl.rcParams['text.usetex']=True\n",
    "mpl.rcParams['text.latex.unicode']=True\n",
    "mpl.rcParams['font.family'] = 'serif' \n",
    "mpl.rcParams['font.serif'] = 'Times New Roman'\n",
    "mpl.rcParams['text.latex.preamble']= ['\\\\usepackage{amsfonts}','\\\\usepackage{amsmath}']\n",
    "mpl.rcParams['font.size'] = 30\n",
    "mpl.rcParams['axes.labelsize']=30\n",
    "mpl.rcParams['legend.fontsize']=30\n",
    "#http://stackoverflow.com/questions/22408237/named-colors-in-matplotlib\n",
    "from utils.misc import getConfigFile, readPickle, loadHDF5, getUniqueIDFromParams\n",
    "from optvaeutils.viz import getName\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalData = loadHDF5('../../expt/evaluateIF_params/wikicorp-pl-2-finopt-if_eval.h5')\n",
    "trainData = loadHDF5('../../expt/evaluateIF_params/wikicorp-pl-2-finopt-if_train.h5')\n",
    "print trainData.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optvaedatasets.load import loadDataset as loadDataset_OVAE\n",
    "dset = loadDataset_OVAE('wikicorp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums_all = np.array(dset['train'].mean(0)).ravel()*100\n",
    "#Rare if occurs in less than 5% of documents\n",
    "widx_rare_all= np.where(sums_all<5)[0]\n",
    "print sums_all.shape, len(widx_rare_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,9))\n",
    "plt.plot(np.sort(sums_all)[::-1])\n",
    "#plt.xticks(np.arange(0,20002,4000), rotation='vertical')\n",
    "plt.axhline(5,ls='--',lw=2,)\n",
    "plt.ylabel('\\\\% of occurence in documents')\n",
    "plt.title('Wikipedia')\n",
    "plt.xlabel('Word Indices')\n",
    "plt.savefig('wiki-sparse.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr, pearsonr\n",
    "from matplotlib.ticker import NullFormatter\n",
    "def KL(mu_0, cov_0, mu_f, cov_f):\n",
    "    assert np.all(cov_0>0.),'should be positive'\n",
    "    assert np.all(cov_f>0.),'should be positive'\n",
    "    diff_mu = mu_f-mu_0\n",
    "    KL      = np.log(cov_f)-np.log(cov_0) - 1. + cov_0/cov_f + diff_mu**2/cov_f\n",
    "    KL_t    = 0.5*KL.sum(1)\n",
    "    return KL_t\n",
    "def normalize(v):\n",
    "    vmx, vmn = v.max(), v.min()\n",
    "    return (v-vmn)/(vmx-vmn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data        = trainData['data']\n",
    "klvec_train = KL(trainData['mu_0'],np.exp(trainData['logcov_0']),trainData['mu_f'],np.exp(trainData['logcov_f']))\n",
    "data        = data[:20000]\n",
    "klvec_train = klvec_train[:20000]\n",
    "\n",
    "#sums        = np.array(data.sum(0)).ravel()\n",
    "#widx_rare   = np.where(sums<1000)[0]\n",
    "n_rare_words_train = data[:,widx_rare_all].sum(1)\n",
    "print n_rare_words_train, len(widx_rare_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data              = evalData['data']\n",
    "klvec_eval        = KL(evalData['mu_0'],np.exp(evalData['logcov_0']),evalData['mu_f'],np.exp(evalData['logcov_f']))\n",
    "\n",
    "data              = data[:20000]\n",
    "klvec_eval        = klvec_eval[:20000]\n",
    "#sums              = np.array(data.sum(0)).ravel()\n",
    "#widx_rare         = np.where(sums<1000)[0]\n",
    "n_rare_words_eval = data[:,widx_rare_all].sum(1)\n",
    "print n_rare_words_eval, len(widx_rare_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axlist = plt.subplots(1,2,figsize=(10,4))\n",
    "\n",
    "ax = axlist.ravel()[0]\n",
    "idx_s = np.argsort(klvec_train)[::-1]\n",
    "print idx_s.shape\n",
    "ax.plot(np.arange(20000),normalize(klvec_train[idx_s]),alpha=0.5,marker='*',lw=0.1,ms=5)\n",
    "ax.scatter(np.arange(20000),normalize(n_rare_words_train[idx_s]),alpha=0.03,s=5,c='r')\n",
    "print spearmanr(n_rare_words_train, b=klvec_train)\n",
    "ax.set_ylabel('Normalized Values')\n",
    "ax.set_xlabel('Train')\n",
    "    \n",
    "ax = axlist.ravel()[1]\n",
    "idx_s = np.argsort(klvec_eval)[::-1]\n",
    "ax.plot(np.arange(20000),normalize(klvec_eval[idx_s]),alpha=0.5,marker='*',lw=0.1,ms=5,label='$\\\\text{KL}(\\\\psi(x)||\\\\psi^*)$')\n",
    "ax.scatter(np.arange(20000),normalize(n_rare_words_eval[idx_s]),alpha=0.03,s=5,c='r',label='Rare Words Counts')\n",
    "leg = ax.legend(bbox_to_anchor=(0.95, 1.4), columnspacing=0.1, ncol=2, markerscale=4)\n",
    "for lh in leg.legendHandles: \n",
    "    lh.set_alpha(1)\n",
    "print spearmanr(n_rare_words_eval, b=klvec_eval)\n",
    "ax.set_xlabel('Held-out')\n",
    "\n",
    "for ax in axlist:\n",
    "    ax.set_yticks(np.arange(0,1.1,0.2))\n",
    "    plt.sca(ax)\n",
    "    plt.xticks(np.arange(0,20001,4000),[str(k)+'k' for k in np.arange(0,20001,4000)/1000],rotation=45)\n",
    "#plt.show()\n",
    "#plt.savefig('normalized_kl_vs_docs.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(8,8))\n",
    "\n",
    "#ax = axlist.ravel()[0]\n",
    "idx_s = np.argsort(klvec_train)[::-1]\n",
    "print idx_s.shape\n",
    "ax.plot(np.arange(20000),normalize(klvec_train[idx_s]),alpha=0.5,marker='*',lw=0.1,ms=5)\n",
    "ax.scatter(np.arange(20000),normalize(n_rare_words_train[idx_s]),alpha=0.03,s=5,c='r')\n",
    "print spearmanr(n_rare_words_train, b=klvec_train)\n",
    "ax.set_ylabel('Normalized Values')\n",
    "ax.set_xlabel('Train')\n",
    "\n",
    "#ax = plt.gca()\n",
    "axins = zoomed_inset_axes(ax, 2, loc=1) # zoom = 6\n",
    "axins.plot(np.arange(20000),normalize(klvec_train[idx_s]),alpha=0.5,marker='*',lw=0.1,ms=5,label='$\\\\text{KL}(\\\\psi(x)||\\\\psi^*)$')\n",
    "axins.scatter(np.arange(20000),normalize(n_rare_words_train[idx_s]),alpha=0.03,s=5,c='r',label='Rare Words')\n",
    "leg = axins.legend(bbox_to_anchor=(0.15, 0.5), columnspacing=0.1, ncol=1, markerscale=4)\n",
    "for lh in leg.legendHandles: \n",
    "    lh.set_alpha(1)\n",
    "axins.set_xlim(0, 8000)\n",
    "axins.set_ylim(0, 0.4)\n",
    "axins.set_xticks([])\n",
    "axins.set_yticks([])\n",
    "mark_inset(ax, axins, loc1=2, loc2=4, fc=\"none\", ec=\"k\",lw=1)\n",
    "\n",
    "ax.set_yticks(np.arange(0,1.1,0.2))\n",
    "plt.sca(ax)\n",
    "plt.xticks(np.arange(0,20001,4000),[str(k)+'k' for k in np.arange(0,20001,4000)/1000],rotation=45)\n",
    "#plt.show()\n",
    "plt.savefig('normalized_kl_vs_docs-train.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(8,8))\n",
    "\n",
    "#ax = axlist.ravel()[0]\n",
    "idx_s = np.argsort(klvec_eval)[::-1]\n",
    "print idx_s.shape\n",
    "ax.plot(np.arange(20000),normalize(klvec_eval[idx_s]),alpha=0.5,marker='*',lw=0.1,ms=5)\n",
    "ax.scatter(np.arange(20000),normalize(n_rare_words_eval[idx_s]),alpha=0.03,s=5,c='r')\n",
    "print spearmanr(n_rare_words_train, b=klvec_train)\n",
    "ax.set_ylabel('Normalized Values')\n",
    "ax.set_xlabel('Held-out')\n",
    "\n",
    "#ax = plt.gca()\n",
    "axins = zoomed_inset_axes(ax, 2, loc=1) # zoom = 6\n",
    "axins.plot(np.arange(20000),normalize(klvec_eval[idx_s]),alpha=0.5,marker='*',lw=0.1,ms=5,label='$\\\\text{KL}(\\\\psi(x)||\\\\psi^*)$')\n",
    "axins.scatter(np.arange(20000),normalize(n_rare_words_eval[idx_s]),alpha=0.03,s=5,c='r',label='Rare Words')\n",
    "leg = axins.legend(bbox_to_anchor=(0.15, 0.5), columnspacing=0.1, ncol=1, markerscale=4)\n",
    "for lh in leg.legendHandles: \n",
    "    lh.set_alpha(1)\n",
    "axins.set_xlim(0, 8000)\n",
    "axins.set_ylim(0, 0.4)\n",
    "axins.set_xticks([])\n",
    "axins.set_yticks([])\n",
    "mark_inset(ax, axins, loc1=2, loc2=4, fc=\"none\", ec=\"k\",lw=1)\n",
    "\n",
    "ax.set_yticks(np.arange(0,1.1,0.2))\n",
    "plt.sca(ax)\n",
    "plt.xticks(np.arange(0,20001,4000),[str(k)+'k' for k in np.arange(0,20001,4000)/1000],rotation=45)\n",
    "#plt.show()\n",
    "plt.savefig('normalized_kl_vs_docs-eval.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evall = 'Held-out\\n$\\\\rho = $ %.2f'%(spearmanr(n_rare_words_eval, b=klvec_eval).correlation)\n",
    "trainl = 'Train\\n$\\\\rho = $ %.2f'%(spearmanr(n_rare_words_train, b=klvec_train).correlation)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(n_rare_words_eval,klvec_eval,s=6,c='b',marker='s',alpha=0.5,label=evall)\n",
    "plt.scatter(n_rare_words_train,klvec_train,s=6,c='darkseagreen',edgecolor = None,alpha=0.5,label=trainl)\n",
    "plt.xticks(np.arange(0,4001,1000),[str(k/1000)+'k' for k in np.arange(0,4001,1000)],rotation='45')\n",
    "plt.yticks(np.arange(0,400,100))\n",
    "plt.xlim([0,4000])\n",
    "plt.ylim([0,400])\n",
    "plt.xlabel('Number of Rare Words')\n",
    "plt.ylabel('$\\\\text{KL}(\\\\psi(x)||\\\\psi_{\\\\text{opt}})$')\n",
    "plt.legend(loc='best', bbox_to_anchor=(.45, 0.6),ncol=1,columnspacing=0.01, markerscale=6, prop={'size': 30},frameon=True)\n",
    "\n",
    "\n",
    "ax = plt.gca()\n",
    "axins = zoomed_inset_axes(ax, 2, loc=4) # zoom = 6\n",
    "#axins.imshow(Z2, extent=extent, interpolation=\"nearest\", origin=\"lower\")\n",
    "# sub region of the original image\n",
    "axins.scatter(n_rare_words_eval,klvec_eval,s=6,c='b',marker='s',alpha=0.5,label=evall)\n",
    "axins.scatter(n_rare_words_train,klvec_train,s=6,c='darkseagreen',edgecolor = None,alpha=0.2,label=trainl)\n",
    "axins.set_xlim(1, 1000)\n",
    "axins.set_ylim(1, 100)\n",
    "axins.set_xticks([])\n",
    "axins.set_yticks([])\n",
    "mark_inset(ax, axins, loc1=2, loc2=4, fc=\"none\", ec=\"k\",lw=1)\n",
    "\n",
    "plt.savefig('kl_n_rare_words.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
